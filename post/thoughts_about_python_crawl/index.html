<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>对Python及爬虫行业的思考 - Jun's Blog</title>
<meta name=theme-color><meta name=description content="前言 最近在帮兄弟大学做一个关于机器学习的项目，其实我做的工作和人工智能半点关系也没有，主要就是用Python做爬虫帮他们爬取一些公开信息。其"><meta name=author content="Jun"><link rel="preload stylesheet" as=style href=https://www.junz.org/main.min.css><link rel=preload as=image href=https://www.junz.org/theme.png><script defer src=https://www.junz.org/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://www.junz.org/favicon.ico><link rel=apple-touch-icon href=https://www.junz.org/apple-touch-icon.png><meta name=generator content="Hugo 0.121.1"><meta itemprop=name content="对Python及爬虫行业的思考"><meta itemprop=description content="前言 最近在帮兄弟大学做一个关于机器学习的项目，其实我做的工作和人工智能半点关系也没有，主要就是用Python做爬虫帮他们爬取一些公开信息。其"><meta itemprop=datePublished content="2021-04-03T20:30:35+08:00"><meta itemprop=dateModified content="2021-04-03T20:30:35+08:00"><meta itemprop=wordCount content="2565"><meta itemprop=keywords content="个人思考,Python,爬虫,"><meta name=twitter:card content="summary"><meta name=twitter:title content="对Python及爬虫行业的思考"><meta name=twitter:description content="前言 最近在帮兄弟大学做一个关于机器学习的项目，其实我做的工作和人工智能半点关系也没有，主要就是用Python做爬虫帮他们爬取一些公开信息。其"><link rel=canonical href=https://www.junz.org/post/thoughts_about_python_crawl/></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-3xl px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-x-[1px] -translate-y-[1px] text-2xl font-semibold" href=https://www.junz.org>Jun's Blog</a><div class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6"><a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/>Home</a>
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-3xl px-8 pb-16 pt-12 dark:prose-invert"><article><header class=mb-16><h1 class="!my-0 pb-2.5">对Python及爬虫行业的思考</h1><div class="text-sm antialiased opacity-60"><time>Apr 3, 2021</time>
<span class=mx-1>&#183;</span>
<span>Jun</span></div></header><section><h2 id=前言>前言</h2><p>最近在帮兄弟大学做一个关于机器学习的项目，其实我做的工作和人工智能半点关系也没有，主要就是用Python做爬虫帮他们爬取一些公开信息。其实很久之前我就决心不再参与任何爬虫项目了，但这次因为一些原因我还是选择了参加。随着我在这个项目上花的时间越来越多，我对Python爬虫这个行业也思考的越来越多。在这里我从自己接触Python开始，谈一下自己对Python爬虫以及市面上的一些培训班的想法。</p><h2 id=初识python>初识Python</h2><p>在我上高中的时候很喜欢折腾一些关于IT的东西，其中就涉及到了做网站。当时在各大论坛及QQ群里都会听到他们说<code>采集</code>这个词。当时的我可以说是什么都不懂，只感觉这个词听上去就很高级。又自以为如果有一种方法可以把网上各种有趣的信息都“采集”到自己手上岂不是太棒了？于是好学的我便开始在Google上搜索相关的文章。很快我便了解到了Python这个语言以及“爬虫”这个词。只要在搜索引擎上搜索“Python 爬虫”，就会一大堆文章，教程，资料。</p><h2 id=学习python爬虫>学习Python爬虫</h2><p>在我了解到世上还有Python和爬虫这么有趣的东西后，我便开始在网上搜索各种教程（记得没错的话，当时主要看的是廖雪峰），以及加了各种学习群，在网盘上存了一堆视频和电子书。当时在上高中，学习十分紧张，我就每天中午和晚上回家时利用加起来不到1个小时的时间在手机上看关于Python的各种教程和文章。在这里不禁感慨当时母亲大人对我使用手机的管制，我们当时还经常因为这个事情吵架。可她怎么会知道我其实一直都是用手机在学习呢？（哈哈哈） 经过一年多断断续续的学习，看电子书和博客教程，我终于零基础入门了编程，从<code>requests</code>库都不知道是啥到可以自己独立写一个简单的爬虫了。</p><h2 id=初遇爬虫瓶颈>初遇爬虫瓶颈</h2><p>在我能够自己写出一个爬取漂亮小姐姐图片的爬虫后，我并没有满足，而是尝试去写各种其他的爬虫。但很快我就发现爬虫并没有我想的那么简单。真正的爬虫并不是简单地获取网页，解析网页，下载数据就行的。在搜索了一些文章后，我发现原来真正的网站都是有反爬措施的，如果想要拿到数据的话，就必须要逆向它的JavaScript代码，获取它加密参数或者是数据的算法。于是看来我除了学习如何逆向JavaScript代码没有任何选择了，但是那个时候已经邻近高考了，我没有时间和精力再去一门新的语言了，所以我心里默默地把这个计划延迟到了高考后的那个暑假。在此之前，我所做的就是看看菜鸟教程和廖雪峰的博客，简单了解下JavaScript的基本使用。</p><h2 id=开始学习反反爬虫>开始学习反反爬虫</h2><p>时间一转，我就已经高中毕业了。记得在等待高考成绩公布的那段日子，我每天干的事情就是学习JavaScript（当时看的是JavaScript高级程序设计这本书）然后还买了一个培训机构的课和知识星球。（没听错，我真的氪金了，还氪了不少）可我真正去看了他们的公开课之后，我发现它所教给我的，并不能真正地能帮我过掉那些网站的反爬虫措施。它所教我的，不过是告诉我谷歌浏览器的DevTools用法，如何调试网页，以及一些常用套路罢了。当然，利用这些技巧，确实可以过掉一些非常低级的反爬虫，可对于行业内有名的，有价值的反爬虫，丝毫没有帮助。还想继续学吗？请购买我们的进阶课程，只要1999。我逐渐开始意识到爬虫界的水比我要想的深得多的多。再加上那段时间发生的其他事情，我逐渐决定放弃爬虫这条路了。</p><p>其中原因有下面几点：</p><ol><li><p>爬虫的关键点并不在于“爬”，而是在于如何过掉别人的反爬虫，或者说如何逆向别人的JavaScript代码。而你在这个过程中，是单枪匹马一个人，对方则是有一个专业的团队在维护者。而且，你作为爬虫方，相当地被动，只要对面对逻辑进行稍稍变化，你就无法顺利拿到数据，只能重新开始分析。</p></li><li><p>法律问题。爬虫在国内可以说是一个相当灰色的行业，并没有完善的法律法规去规范这个行业。有相当一部分人因为爬虫而进了监狱。你可能会说，我只要不去爬一些敏感的数据，不去采集一些个人信息，就不用担心这个问题。可我却认为，只要你动了别人的蛋糕，他们就有能力通过强大的法务团队将你送进监狱。这并不是危言悚听，只要你仔细关注下新闻你就可以发现，有很多开发者就是因为动了一些大公司的利益，被迫停掉了自己手上的项目，更有甚者，赔款，进监狱。</p></li></ol><h2 id=思考>思考</h2><p>市面上编程语言那么多，为什么那么多培训机构都要打着Python爬虫的口号呢？我个人认为原因很简单也很直接：首先Python的语法相当于Java C++更简单，流畅，适合初学者学习，而在Python众多领域中，爬虫又是最容易教的。从我加入的那些爬虫交流群来看，很多购买培训班课程的人都是非科班出身，想想看生活的压力，培训班的诱人的广告，让他们不禁动了心，想通过自学编程这条路成功。</p><p>然而事实真的有培训班老师所宣传的那么美好么？在购买培训班课程后有多少人真正去学了呢？而那些真正去学了的人又有多少拿到心中的offer呢？就我自己来说，因为我是有一点基础的，所以我学起来他们的课程并没有那么吃力，但我最后也还是选择了放弃。</p><p>在今天爬虫行业的金字塔上，在顶层的，是一些身怀绝技的大神，他们可以轻松破掉那些没有人性的加密与混淆，拿到想要的数据和高薪；在底层的，则是一大堆非科班，非专业的韭菜们。他们想通过编程这条路改变命运，却又缺乏专业知识，只会一些非常基本的知识。与其说他们是爬虫工程师，不如说他们是xpath工程师。而介于两者之间的，则是唯利是图的培训班们，他们在各种平台散播各种广告，利用所谓的学习资料吸引大量前面所说的韭菜们，可又没办法交给他们一些真正有价值的知识（高级的反反爬虫可能侵犯到一些商业公司的利益）我这里只是说Python爬虫，但我相信其他的很多培训班也都大差不差。</p><p>我知道在当前这个如此内卷的社会中，大家都想急切地赚大钱，过上好生活，改变自己的命运。可是，这个世界上没有能轻而易举达到的成功，如果有，也不会绝对不会属于你。与其想找到某个所谓的捷径，不如静下心来花时间慢慢提升自己。随着时间的推移，再小的进步都可以像滚雪球一样被积累成质的改变。</p><h2 id=后话>后话</h2><p>这些就是我个人的一些思考了，可能很不成熟，也可能漏洞百出，但这真的是我自己在这些事情中独立的一些观察和思考。在帮老师做完这个项目之后，我就不打算接触任何与爬虫相关的东西了。希望以后可以做好开发岗，build some cool stuff!</p></section><footer class="mt-12 flex flex-wrap"><a class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]" href=https://www.junz.org/tags/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83>个人思考</a>
<a class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]" href=https://www.junz.org/tags/python>Python</a>
<a class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]" href=https://www.junz.org/tags/%E7%88%AC%E8%99%AB>爬虫</a></footer><nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]"><a class="flex w-1/2 items-center rounded-l-md p-6 pr-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://www.junz.org/post/linked_list_in_redis/><span class=mr-1.5>←</span><span>由Redis学习数据结构--链表</span></a>
<a class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://www.junz.org/post/practical_vim/><span>Vim实用技巧</span><span class=ml-1.5>→</span></a></nav></article></main><footer class="opaco mx-auto flex h-[4.5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"><div class=mr-auto>&copy; 2023
<a class=link href=https://www.junz.org>Jun's Blog</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>✎ Paper</a></footer></body></html>